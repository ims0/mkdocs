[toc]

# 语言类（C++）：

## STL原理及实现：
STL各类型容器实现，STL共有六大组件
+ STL提供六大组件，彼此可以组合套用：

1.  容器（Containers）：各种数据结构，如：序列式容器vector、list、deque、关联式容器set、map、multiset、multimap。用来存放数据。从实现的角度来看，STL容器是一种class template。

2.  算法（algorithms）：各种常用算法，如：sort、search、copy、erase。从实现的角度来看，STL算法是一种 function template。注意一个问题：任何的一个STL算法，都需要获得由一对迭代器所标示的区间，用来表示操作范围。这一对迭代器所标示的区间都是前闭后开区间，例如[first, last)

3.  迭代器（iterators）：容器与算法之间的胶合剂，是所谓的“泛型指针”。共有五种类型，以及其他衍生变化。从实现的角度来看，迭代器是一种将 operator*、operator->、operator++、operator- - 等指针相关操作进行重载的class template。所有STL容器都有自己专属的迭代器，只有容器本身才知道如何遍历自己的元素。原生指针(native pointer)也是一种迭代器。

4.  仿函数（functors）：行为类似函数，可作为算法的某种策略（policy）。从实现的角度来看，仿函数是一种重载了operator（）的class或class template。一般的函数指针也可视为狭义的仿函数。

5.  配接器（adapters）：一种用来修饰容器、仿函数、迭代器接口的东西。例如：STL提供的queue 和 stack，虽然看似容器，但其实只能算是一种容器配接器，因为它们的底部完全借助deque，所有操作都由底层的deque供应。改变 functors接口者，称为function adapter；改变 container 接口者，称为container adapter；改变iterator接口者，称为iterator adapter。

6.  配置器（allocators）：负责空间配置与管理。从实现的角度来看，配置器是一个实现了动态空间配置、空间管理、空间释放的class template。

这六大组件的交互关系：container（容器） 通过 allocator（配置器） 取得数据储存空间，algorithm（算法）通过 iterator（迭代器）存取 container（容器） 内容，functor（仿函数） 可以协助 algorithm（算法） 完成不同的策略变化，adapter（配接器） 可以修饰或套接 functor（仿函数）

* 序列式容器：
    vector-数组，元素不够时再重新分配内存，拷贝原来数组的元素到新分配的数组中。
    list－单链表。
    deque-分配中央控制器map(并非map容器)，map记录着一系列的固定长度的数组的地址. 记住这个map仅仅保存的是数组的地址,真正的数据在数组中存放着. deque先从map中央的位置(因为双向队列，前后都可以插入元素)找到一个数组地址，向该数组中放入数据，数组不够时继续在map中找空闲的数组来存数据。当map也不够时重新分配内存当作新的map,把原来map中的内容copy的新map中。所以使用deque的复杂度要大于vector，尽量使用vector。

stack-基于deque。
    queue-基于deque。
    heap-完全二叉树，使用最大堆排序，以数组(vector)的形式存放。
    priority_queue-基于heap。
    slist-双向链表。

* 关联式容器：
    1. set,map,multiset,multimap-基于红黑树(RB-tree)，
    一种加上了额外平衡条件的二叉搜索树。
    2. hash_map,hash_set,hash_multiset,hash_multimap-基于hashtable。
    hash table-散列表:
       将待存数据的key经过映射函数变成一个数组(一般是vector)的索引，例如：数据的key%数组的大小＝数组的索引(一般文本通过算法也可以转换为数字)，然后将数据当作此索引的数组元素。有些数据的key经过算法的转换可能是同一个数组的索引值(碰撞问题，可以用线性探测，二次探测来解决)，STL是用开链的方法来解决的，每一个数组的元素维护一个list，他把相同索引值的数据存入一个list，这样当list比较短时执行**删除，插入，搜索**等算法比较快。


 * [STL六大组件](http://blog.csdn.net/chenguolinblog/article/details/30336805)

什么是“标准非STL容器”？

list和vector有什么区别？

+ vector拥有一段连续的内存空间，因此支持随机存取，如果需要高效的随即存取，而不在乎插入和删除的效率，使用vector。
+ list拥有一段不连续的内存空间，因此不支持随机存取，如果需要大量的插入和删除，而不关心随即存取，则应使用list。

## 虚函数：
虚函数的作用和实现原理，什么是虚函数,有什么作用?

+ C++的多态分为静态多态（编译时多态）和动态多态（运行时多态）两大类。
1. 静态多态通过**重载、模板**来实现；
2. 动态多态就是通过本文的主角**虚函数**来体现的。

### 虚函数实现原理:包括虚函数表、虚函数指针等

+ 虚函数的作用说白了就是：当调用一个虚函数时，被执行的代码必须和调用函数的对象的动态类型相一致。编译器需要做的就是如何高效的实现提供这种特性。不同编译器实现细节也不相同。大多数编译器通过vtbl（*virtual table*）和vptr（*virtual table pointer*）来实现的。 当一个类声明了虚函数或者继承了虚函数，这个类就会有自己的vtbl。vtbl实际上就是一个函数指针数组，有的编译器用的是链表，不过方法都是差不多。vtbl数组中的每一个元素对应一个函数指针指向该类的一个虚函数，同时该类的每一个对象都会包含一个vptr，vptr指向该vtbl的地址。

结论：
+ 每个声明了虚函数或者继承了虚函数的类，都会有一个自己的vtbl
    同时该类的每个对象都会包含一个vptr去指向该vtbl
    虚函数按照其声明顺序放于vtbl表中, vtbl数组中的每一个元素对应一个函数指针指向该类的虚函数
    如果子类覆盖了父类的虚函数，将被放到了虚表中原来父类虚函数的位置
    在多继承的情况下，每个父类都有自己的虚表。子类的成员函数被放到了第一个父类的表中

衍生问题:为什么 C++里访问虚函数比访问普通函数慢?

 + 单继承时性能差不多，多继承的时候会慢

### 调用性能方面

从前面虚函数的调用过程可知。当调用虚函数时过程如下（引自More Effective C++）:

+ **通过对象的 vptr 找到类的 vtbl**。这是一个简单的操作,因为编译器知道在对象内 哪里能找到 vptr(毕竟是由编译器放置的它们)。因此这个代价只是一个偏移调整(以得到 vptr)和一个指针的间接寻址(以得到 vtbl)。
    找到对应 vtbl 内的指向被调用函数的指针。这也是很简单的, 因为编译器为每个虚函数在 vtbl 内分配了一个唯一的索引。这步的代价只是在 vtbl 数组内 的一个偏移。
调用第二步找到的的指针所指向的函数。
+ 在单继承的情况下，调用虚函数所需的代价基本上和非虚函数效率一样，在大多数计算机上它多执行了很少的一些指令，所以有很多人一概而论说虚函数性能不行是不太科学的。在多继承的情况下，由于会根据多个父类生成多个vptr，在对象里为寻找 vptr 而进行的偏移量计算会变得复杂一些，但这些并不是虚函数的性能瓶颈。 虚函数运行时所需的代价主要是虚函数不能是内联函。这也是非常好理解的，是因为内联函数是指在编译期间用被调用的函数体本身来代替函数调用的指令，但是虚函数的“虚”是指“直到运行时才能知道要调用的是哪一个函数。”但虚函数的运行时多态特性就是要在运行时才知道具体调用哪个虚函数，所以没法在编译时进行内联函数展开。当然如果通过对象直接调用虚函数它是可以被内联，但是大多数虚函数是通过对象的指针或引用被调用的，这种调用不能被内联。 因为这种调用是标准的调用方式，所以虚函数实际上不能被内联。

### 占用空间方面

在上面的虚函数实现原理部分，可以看到为了实现运行时多态机制，编译器会给每一个包含虚函数或继承了虚函数的类自动建立一个虚函数表，**所以虚函数的一个代价就是会增加类的体积**。在虚函数接口较少的类中这个代价并不明显，虚函数表vtbl的体积相当于几个函数指针的体积，如果你有大量的类或者在每个类中有大量的虚函数,你会发现 vtbl 会占用大量的地址空间。但这并不是最主要的代价，主要的代价是发生在类的继承过程中，在上面的分析中，可以看到，当子类继承父类的虚函数时，子类会有自己的vtbl，如果子类只覆盖父类的一两个虚函数接口，子类vtbl的其余部分内容会与父类重复。这在如果存在大量的子类继承，且重写父类的虚函数接口只占总数的一小部分的情况下，会造成大量地址空间浪费。在一些GUI库上这种大量子类继承自同一父类且只覆盖其中一两个虚函数的情况是经常有的，这样就导致UI库的占用内存明显变大。 由于虚函数指针vptr的存在，虚函数也会增加该类的每个对象的体积。在单继承或没有继承的情况下，类的每个对象会多一个vptr指针的体积，也就是4个字节；在多继承的情况下，类的每个对象会多N个（N＝包含虚函数的父类个数）vptr的体积，也就是4N个字节。当一个类的对象体积较大时，这个代价不是很明显，但当一个类的对象很轻量的时候，如成员变量只有4个字节，那么再加上4（或4N）个字节的vptr，对象的体积相当于翻了1（或N）倍，这个代价是非常大的。

[C++虚函数浅析](http://glgjing.github.io/blog/2015/01/03/c-plus-plus-xu-han-shu-qian-xi/)

### 纯虚函数，为什么需要纯虚函数？

+ 纯虚函数是在基类中声明的虚函数，它在基类中没有定义，但要求任何派生类都要定义自己的实现方法。在基类中实现纯虚函数的方法是在函数原型后加“=0”

    virtual void funtion1()=0

 原因：
 1、为了方便使用多态特性，我们常常需要在基类中定义虚拟函数。
 2、在很多情况下，基类本身生成对象是不合情理的。例如，动物作为一个基类可以派生出老虎、孔雀等子类，但动物本身生成对象明显不合常理。

 为了解决上述问题，引入了纯虚函数的概念，将函数定义为纯虚函数（方法：virtual ReturnType Function()= 0;），则编译器要求在派生类中必须予以重写以实现多态性。同时含有纯虚拟函数的类称为**抽象类**，它不能生成对象。这样就很好地解决了上述两个问题。声明了纯虚函数的类是一个抽象类。所以，用户不能创建类的实例，只能创建它的派生类的实例。

 + 定义纯虚函数的目的在于，使派生类仅仅只是继承函数的接口。
    纯虚函数的意义，让所有的类对象（主要是派生类对象）都可以执行纯虚函数的动作，但类无法为纯虚函数提供一个合理的缺省实现。所以类纯虚函数的声明就是在告诉子类的设计者，“你必须提供一个纯虚函数的实现，但我不知道你会怎样实现它”。

### [虚函数和纯虚函数的区别](http://blog.csdn.net/hackbuteer1/article/details/7558868)

### 什么类需要定义虚析构函数?

1. 带多态性质的Base类需要virtual 析构函数，如果class带有任何virtual 函数，它就应该拥有一个virtual析构函数。
2. Class 的目的如果不是作为 Base Class 使用，或不是为了具备多态性质，就不该声明 virtual 析构函数。

当然，并不是要把所有类的析构函数都写成虚函数。因为当类里面有虚函数的时候，
编译器会给类添加一个虚函数表，里面来存放虚函数指针，也会给带虚函数的类的对象增加虚表指针，这样类，和类的对象d体积都增加了。
所以，只有当一个类被用来作为基类的时候，才把析构函数写成虚函数。

### 内联函数、构造函数、静态成员函数可以是虚函数吗?

+ **inline, static, constructor**三种函数都不能带有**virtual**关键字。
    inline是编译时展开，必须有实体；
    static属于class自己的，也必须有实体；
    virtual函数基于vtable（内存空间），constructor函数如果是virtual的，调用时也需要根据vtable寻找，但是constructor是virtual的情况下是找不到的，因为constructor自己本身都不存在了，创建不到class的实例，没有实例，class的成员（除了public static/protected static for friend class/functions，其余无论是否virtual）都不能被访问了。

    虚函数实际上不能被内联:虚函数运行时所需的代价主要是虚函数不能是内联函。这也是非常好理解的，是因为内联函数是指在编译期间用被调用的函数体本身来代替函数调用的指令，但是虚函数的“虚”是指“直到运行时才能知道要调用的是哪一个函数。”但虚函数的运行时多态特性就是要在运行时才知道具体调用哪个虚函数，所以没法在编译时进行内联函数展开。当然如果通过对象直接调用虚函数它是可以被内联，但是大多数虚函数是通过对象的指针或引用被调用的，这种调用不能被内联。 因为这种调用是标准的调用方式，所以虚函数实际上不能被内联。

    **构造函数不能是虚函数**。而且，在构造函数中调用虚函数，实际执行的是父类的对应函数，因为自己还没有构造好, 多态是被disable的。

    **静态的对象是属于整个类的**，不对某一个对象而言，同时其函数的指针存放也不同于一般的成员函数，其无法成为一个对象的虚函数的指针以实现由此带来的动态机制。
构造函数中可以调用虚函数吗?


### 最后，总结一下关于虚函数的一些常见问题：

1. 虚函数是动态绑定的，也就是说，使用虚函数的指针和引用能够正确找到实际类的对应函数，而不是执行定义类的函数。这是虚函数的基本功能，就不再解释了。
2. 构造函数不能是虚函数。而且，在构造函数中调用虚函数，实际执行的是父类的对应函数，因为自己还没有构造好, 多态是被disable的。
3. 析构函数可以是虚函数，而且，在一个复杂类结构中，这往往是必须的。
4. 将一个函数定义为纯虚函数，实际上是将这个类定义为抽象类，不能实例化对象。
5. 纯虚函数通常没有定义体，但也完全可以拥有。
6.  析构函数可以是纯虚的，但纯虚析构函数必须有定义体，因为析构函数的调用是在子类中隐含的。

```
#include<iostream>
class Base{
    public:
        virtual ~Base()=0;
};
Base::~Base()
{
    std::cout<<"~Base()"<<std::endl;
}
class Drive :public Base{
    public:
        virtual ~Drive(){};
};
int main()
{
    Drive d;
    return 0;
}
```

7. 非纯的虚函数必须有定义体，不然是一个错误。

8. 派生类的override虚函数定义必须和父类完全一致。除了一个特例，如果父类中返回值是一个指针或引用，子类override时可以返回这个指针（或引用）的派生。例如，在上面的例子中，在Base中定义了 virtual Base* clone(); 在Derived中可以定义为 virtual Derived* clone()。可以看到，这种放松对于Clone模式是非常有用的。
[虚析构函数(√)、纯虚析构函数(√)、虚构造函数(X)](http://www.cnblogs.com/chio/archive/2007/09/10/888260.html)

### 为什么需要虚继承?虚继承实现原理解析

+ 虚拟继承是多重继承中特有的概念。虚拟基类是为解决多重继承而出现的。
    如:类D继承自类B1、B2，而类B1、B2都继 承自类A，因此在**类D中两次出现类A中的变量和函数**。为了节省内存空间，可以将B1、B2对A的继承定义为虚拟继承，而A就成了虚拟基类,虚拟继承在一般的应用中很少用到，所以也往往被忽视，这也主要是因为在C++中，多重继承是不推荐的，也并不常用，而一旦离开了多重继承，虚拟继承就完全失去了存在的必要因为这样只会降低效率和占用更多的空间。

    虚继承的特点是，在任何派生类中的virtual基类总用同一个（共享）对象表示，
[C++虚拟继承](http://blog.csdn.net/hyg0811/article/details/11951855)

## 设计模式：

C++单例模式写法:

+ 静态化并不是单例 (Singleton) 模式:

第一, 静态成员变量初始化顺序不依赖构造函数, 得看编译器心情的, 没法保证初始化顺序 (极端情况: 有 a b 两个成员对象, b 需要把 a 作为初始化参数传入, 你的类就 必须 得要有构造函数, 并确保初始化顺序). 

第二, 最严重的问题, 失去了面对对象的重要特性 -- "多态", 静态成员方法不可能是 virtual 的.  Log 类的子类没法享受 "多态" 带来的便利.

```
class Log {
public:
    static void Write(char const *logline);
    static bool SaveTo(char const *filename);
private:
    static std::list<std::string> m_data;
};

In log. cpp we need to add
std::list<std::string> Log::m_data;

```

**饿汉模式**: 是指单例实例在程序运行时被立即执行初始化:

```
    class Log {
    public:
      static Log* Instance() {
        return &m_pInstance;
      }

      virtual void Write(char const *logline);
      virtual bool SaveTo(char const *filename);

    private:
      Log();              // ctor is hidden
      Log(Log const&);    // copy ctor is hidden

      static Log m_pInstance;
      static std::list<std::string> m_data;
    };
    // in log. cpp we have to add
    Log Log::m_pInstance;
```
 这种模式的问题也很明显, 类现在是多态的, 但静态成员变量初始化顺序还是没保证.

**懒汉模式** (堆-粗糙版): 单例实例只在第一次被使用时进行初始化:
```
    class Log {

    public:
      static Log* Instance() {
        if (!m_pInstance)
          m_pInstance = new Log;
        return m_pInstance;
      }

      virtual void Write(char const *logline);
      virtual bool SaveTo(char const *filename);

    private:
      Log();        // ctor is hidden
      Log(Log const&);    // copy ctor is hidden

      static Log* m_pInstance;
      static std::list<std::string> m_data;
    };
    // in log. cpp we have to add
    Log* Log::m_pInstance = NULL;
```
Instance() 只在第一次被调用时为 m_pInstance 分配内存并初始化.  嗯, 看上去所有的问题都解决了, 初始化顺序有保证, 多态也没问题.
    程序退出时, 析构函数没被执行.  这在某些设计不可靠的系统上会导致资源泄漏, 比如文件句柄, socket 连接, 内存等等
    对于这个问题, 比较土的解决方法是, 给每个 Singleton 类添加一个 destructor() 方法:


+ 懒汉模式 (局部静态变量-最佳版)

它也被称为 Meyers Singleton [Meyers]:
```
#include<iostream>
#include<vector>
class Log {
    public:
        static Log& Instance() {
            static Log singletonLog;
            return singletonLog;
        }
        void Write(char const *logLine){
            m_data.push_back(logLine);
        };
        bool SaveTo(char const *filename);
        bool Print(){
            for( auto &line : m_data ){
                std::cout<<line<<std::endl;
            }
        }
    private:
        Log(){};          // ctor is hidden
        Log(Log const&);      // copy ctor is hidden
        Log& operator=(Log const&);  // assign op is hidden
        static std::vector<std::string> m_data;
};
std::vector<std::string> Log::m_data;
int main()
{
    Log::Instance().Write("hello");
    Log::Instance().Print();
    return 0;
}

```

在 Instance() 函数内定义局部静态变量的好处是, theLog `` 的构造函数只会在第一次调用 ``Instance() 时被初始化, 达到了和 "堆栈版" 相同的动态初始化效果, 保证了成员变量和 Singleton 本身的初始化顺序.

它还有一个潜在的安全措施, Instance() 返回的是对局部静态变量的引用, 如果返回的是指针, Instance() 的调用者很可能会误认为他要检查指针的有效性, 并负责销毁.  构造函数和拷贝构造函数也私有化了, 这样类的使用者不能自行实例化.

另外, 多个不同的 Singleton 实例的析构顺序与构造顺序相反.

[C++ Singleton (单例) 模式最优实现](http://blog.yangyubo.com/2009/06/04/best-cpp-singleton-pattern/)

[C++中的单例模式](http://www.cnblogs.com/xiehongfeng100/p/4781013.html)

### 用C++设计一个不能被继承的类。

+ **构造函数或析构函数为私有函数**，所以该类是无法被继承的，

### 定义一个只能在堆上定义对象的类

+ 只能在堆内存上实例化的类：将**析构函数定义为private**，在栈上不能自动调用析构函数，只能手动调用。也可以将构造函数定义为private，但这样需要手动写一个函数实现对象的构造。

### 定义一个只能在栈上定义对象的类
+ 只能在栈内存上实例化的类：将函数**operator new和operator delete**定义为private，这样使用new操作符创建对象时候，无法调用operator new，delete销毁对象也无法调用operator delete。

[设计一个只能在堆上或栈上实例化的类](http://www.cnblogs.com/luxiaoxun/archive/2012/08/03/2621827.html)


多重类构造和析构的顺序
+ 先调用基类的构造函数，在调用派生类的构造函数
+ 先构造的后析构，后构造的先析构

### 内存分配：

内存分配方式有三种：

1.  从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。例如全局变量，static变量。
2.  在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。
3.  从堆上分配，亦称动态内存分配。程序在运行的时候用malloc或new申请任意多少的内存，程序员自己负责在何时用free或delete释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

c++运行时各类型内存分配（堆，栈，静态区，数据段，BSS，ELF），BSS段，
sizeof一个类求大小（字节对齐原则）、

C++四种强制类型转换，
+ int char float,long long long类型长度
### 指针：

防止指针的越界使用，
+ 必须让指针指向一个有效的内存地址,
1.  防止数组越界
2.  防止向一块内存中拷贝过多的内容
3.  防止使用空指针
4.  防止改变const修改的指针
5.  防止改变指向静态存储区的内容
6.  防止两次释放一个指针
7.  防止使用野指针.

什么是指针退化及防止、

+ 如果用一个数组作为函数入参 比如
```
    void fun(char a[100])
    {
        cout<< sizeof(a) <<endl;
    }
```
指针的移动问题，

+ 指针P ++具体移动的字节数等于指针指向的变量类型大小.

const,volatile修饰指针的含义，
堆和栈上的指针，
    指针所指向的这块内存是在哪里分配的,在堆上称为堆上的指针,在栈上为栈上的指针.
    在堆上的指针,可以保存在全局数据结构中,供不同函数使用访问同一块内存.
    在栈上的指针,在函数退出后,该内存即不可访问.

指针的释放及内存泄露原因，

指针作为函数的参数，函数指针，

指针和引用及地址的区别，数组名，

指针与地址的区别?
+ 区别:
1.  指针意味着已经有一个指针变量存在,他的值是一个地址,指针变量本身也存放在一个长度为四个字节的地址当中,而地址概念本身并不代表有任何变量存在.
2.  指针的值,如果没有限制,通常是可以变化的,也可以指向另外一个地址.
       地址表示内存空间的一个位置点,他是用来赋给指针的,地址本身是没有大小概念,指针指向变量的大小,取决于地址后面存放的变量类型.
    指针与数组名的关系?
    其值都是一个地址,但前者是可以移动的,后者是不可变的.

指针和引用的区别（一般都会问到）

+ 相同点：
1.  都是地址的概念；
    指针指向一块内存，它的内容是所指内存的地址；引用是某块内存的别名。
+ 区别：
1.  指针是一个实体，而引用仅是个别名；

2.  引用使用时无需解引用(*)，指针需要解引用；

3.  引用只能在定义时被初始化一次，之后不可变；指针可变；

4.  引用没有 const，指针有 const；

5.  引用不能为空，指针可以为空；

6.  “sizeof 引用”得到的是所指向的变量(对象)的大小，而“sizeof 指针”得到的是指针本身(所指向的变量或对象的地址)的大小；

7.  指针和引用的自增(++)运算意义不一样；

8.  从内存分配上看：程序为指针变量分配内存区域，而引用不需要分配内存区域。

迭代器与普通指针有什么区别

智能指针的原理,

+ 智能指针：实际指行为类似于指针的类对象 ，它的一种通用实现方法是采用引用计数的方法。
1.  智能指针将一个计数器与类指向的对象相关联，引用计数跟踪共有多少个类对象共享同一指针。
2.  每次创建类的新对象时，初始化指针并将引用计数置为1；
3.  当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数；
4.  对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数；这是因为左侧的指针指向了右侧指针所指向的对象，因此右指针所指向的对象的引用计数+1；
5.  调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）。
6.  实现智能指针有两种经典策略：一是引入辅助类，二是使用句柄类。这里主要讲一下引入辅助类的方法



其他：override和overload的区别，

+ override（重写）
1.  方法名、参数、返回值相同。
2.  子类方法不能缩小父类方法的访问权限。
3.  子类方法不能抛出比父类方法更多的异常(但子类方法可以不抛出异常)。
4.  存在于父类和子类之间。
5.  方法被定义为final不能被重写。
+ overload（重载）
1.  参数类型、个数、顺序至少有一个不相同。
2.  不能重载只有返回值不同的方法名。
3.  存在于父类和子类、同类中。

  Overload是重载的意思，Override是覆盖的意思，也就是重写。

+    重载Overload表示同一个类中可以有多个名称相同的方法，但这些方法的参数列表各不相同（即参数个数或类型不同）。

+    重写Override表示子类中的方法可以与父类中的某个方法的名称和参数完全相同，通过子类创建的实例对象调用这个方法时，将调用子类中的定义方法，这相当于把父类中定义的那个完全相同的方法给覆盖了，这也是面向对象编程的多态性的一种表现。

+    子类覆盖父类的方法时，只能比父类抛出更少的异常，或者是抛出父类抛出的异常的子异常，因为子类可以解决父类的一些问题，不能比父类有更多的问题。子类方法的访问权限只能比父类的更大，不能更小。如果父类的方法是private类型，那么，子类则不存在覆盖的限制，相当于子类中增加了一个全新的方法。


写string类的构造，析构，拷贝函数

    String 类的原型如下
    class String
    {
      public:
             String(const char *str=NULL); //构造函数
             String(const String &other); //拷贝构造函数
             ~String(void); //析构函数
             String& operator=(const String &other); //等号操作符重载
             ShowString();

      private:
             char *m_data; //指针
    };

    String::~String()
    {
       delete [] m_data; //析构函数，释放地址空间
    }
    String::String(const char *str)
    {
       if (str==NULL)//当初始化串不存在的时候，为m_data申请一个空间存放'\0'；
        {
           m_data=new char[1];
           *m_data='\0';
        }
       else//当初始化串存在的时候，为m_data申请同样大小的空间存放该串；
        {
           int length=strlen(str);
           m_data=new char[length+1];
           strcpy(m_data,str);
        }
    }

    String::String(const String &other)//拷贝构造函数，功能与构造函数类似。
    {
       int length=strlen(other. m_data);
       m_data=new [length+1];
       strcpy(m_data,other. m_data);
    }
    String& String::operator =(const String &other)
    {
       if (this==&other)//当地址相同时，直接返回；
           return *this;

       delete [] m_data;//当地址不相同时，删除原来申请的空间，重新开始构造；
       int length=sizeof(other. m_data);
       m_data=new [length+1];
       strcpy(m_data,other. m_data);
       return *this;
    }

    String::ShowString()//由于m_data是私有成员，对象只能通过public成员函数来访问；
    {
         cout<<this->m_data<<endl;
    }

    main()
    {
    String AD;
    char * p="ABCDE";
    String B(p);
    AD. ShowString();
    AD=B;
    AD. ShowString();

    }

1 指针的四要素

1.  指针变量,表示一个内存地址,通常为逻辑地址,与实际的物理地址还有一个映射关系.
2.  指针变量的长度,在WIN32下为四个字节,
3.  指针指向的变量
4.  该内存地址空间下存放的变量,具体内容可能是各种类型的变量.
5.  指针指向的变量的长度,以该内存地址空间开始的内存空间大小.


### 五种I/O 模式，

1. 阻塞I/O           (Linux下的I/O操作默认是阻塞I/O，即open和socket创建的I/O都是阻塞I/O)
2. 非阻塞 I/O        (可以通过fcntl或者open时使用O_NONBLOCK参数，将fd设置为非阻塞的I/O)
3. I/O 多路复用     (I/O多路复用，通常需要非阻塞I/O配合使用)
4. 信号驱动 I/O    (SIGIO)
5.  异步 I/O

Apache 模型（Process Per Connection，简称PPC），TPC（ThreadPer Connection）模型，以及 select 模型和 poll 模型，epoll模型

一般来说，程序进行输入操作有两步：
1. 等待有数据可以读
2. 将数据从系统内核中拷贝到程序的数据区。

对于sock编程来说:
+ 第一步:   一般来说是等待数据从网络上传到本地。当数据包到达的时候，数据将会从网络层拷贝到内核的缓存中；
+ 第二步:   是从内核中把数据拷贝到程序的数据区中。

###  阻塞I/O模式    //进程处于阻塞模式时，让出CPU，进入休眠状态
阻塞 I/O 模式是最普遍使用的 I/O 模式。是Linux系统下缺省的IO模式。
大部分程序使用的都是阻塞模式的 I/O 。
一个套接字建立后所处于的模式就是阻塞 I/O 模式。（因为Linux系统默认的IO模式是阻塞模式）


对于一个UDP 套接字来说，数据就绪的标志比较简单：
+    （1）已经收到了一整个数据报
+    （2）没有收到。

而 TCP 这个概念就比较复杂，需要附加一些其他的变量。
    一个进程调用 recvfrom  ，然后系统调用并不返回知道有数据报到达本地系统，然后系统将数据拷贝到进程的缓存中。（如果系统调用收到一个中断信号，则它的调用会被中断）

我们称这个进程在调用recvfrom一直到从recvfrom返回这段时间是阻塞的。当recvfrom正常返回时，我们的进程继续它的操作


### 非阻塞模式I/O  
  //非阻塞模式的使用并不普遍，因为非阻塞模式会浪费大量的CPU资源。

当我们将一个套接字设置为非阻塞模式，我们相当于告诉了系统内核： “当我请求的I/O 操作不能够马上完成，你想让我的进程进行休眠等待的时候，不要这么做，请马上返回一个错误给我。”
    我们开始对 recvfrom 的三次调用，因为系统还没有接收到网络数据，所以内核马上返回一个EWOULDBLOCK的错误。

第四次我们调用 recvfrom 函数，一个数据报已经到达了，内核将它拷贝到我们的应用程序的缓冲区中，然后 recvfrom 正常返回，我们就可以对接收到的数据进行处理了。
当一个应用程序使用了非阻塞模式的套接字，它需要使用一个循环来不听的测试是否一个文件描述符有数据可读(称做 polling(轮询))。应用程序不停的 polling 内核来检查是否 I/O操作已经就绪。这将是一个极浪费 CPU资源的操作。这种模式使用中不是很普遍。

例如:
    
对管道的操作，最好使用非阻塞方式！



###     I/O多路复用 
  //针对批量IP操作时，使用I/O多路复用，非常有好。

在使用 I/O 多路技术的时候，我们调用select()函数和 poll()函数或epoll函数(2. 6内核开始支持)，在调用它们的时候阻塞，而不是我们来调用 recvfrom（或recv）的时候阻塞。

当我们调用 select函数阻塞的时候，select 函数等待数据报套接字进入读就绪状态。当select函数返回的时候，也就是套接字可以读取数据的时候。这时候我们就可以调用 recvfrom函数来将数据拷贝到我们的程序缓冲区中。
            对于单个I/O操作，和阻塞模式相比较，select()和poll()或epoll并没有什么高级的地方。

而且，在阻塞模式下只需要调用一个函数：

读取或发送函数。
在使用了多路复用技术后，我们需要调用两个函数了：

先调用 select()函数或poll()函数，然后才能进行真正的读写。

+ 多路复用的高级之处在于::

它能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。

#### IO 多路技术一般在下面这些情况中被使用：

1. 当一个客户端需要同时处理多个文件描述符的输入输出操作的时候（一般来说是标准的输入输出和网络套接字)，I/O 多路复用技术将会有机会得到使用。
2. 当程序需要同时进行多个套接字的操作的时候。
3. 如果一个 TCP 服务器程序同时处理正在侦听网络连接的套接字和已经连接好的套接字。
4. 如果一个服务器程序同时使用 TCP 和 UDP 协议。
5. 如果一个服务器同时使用多种服务并且每种服务可能使用不同的协议（比如 inetd就是这样的）。

###  异步IO模式有::

1. 信号驱动I/O模式
2. 异步I/O模式

    信号驱动I/O模式                                                  //自己没有用过。

我们可以使用信号，让内核在文件描述符就绪的时候使用 SIGIO 信号来通知我们。我们将这种模式称为信号驱动 I/O 模式。

为了在一个套接字上使用信号驱动 I/O 操作，下面这三步是所必须的。

（1）一个和 SIGIO信号的处理函数必须设定。
（2）套接字的拥有者必须被设定。一般来说是使用 fcntl 函数的 F_SETOWN 参数来
    进行设定拥有者。
（3）套接字必须被允许使用异步 I/O。一般是通过调用 fcntl 函数的 F_SETFL 命令，O_ASYNC为参数来实现。

虽然设定套接字为异步 I/O 非常简单，但是使用起来困难的部分是怎样在程序中断定产生 SIGIO信号发送给套接字属主的时候，程序处在什么状态。

    1．UDP 套接字的 SIGIO 信号                   (比较简单)
       在 UDP 协议上使用异步 I/O 非常简单．这个信号将会在这个时候产生：
    1、套接字收到了一个数据报的数据包。
    2、套接字发生了异步错误。
            当我们在使用 UDP 套接字异步 I/O 的时候，我们使用 recvfrom()函数来读取数据报数据或是异步 I/O 错误信息。
    2．TCP 套接字的 SIGIO 信号                  (不会使用)
              不幸的是，异步 I/O 几乎对 TCP 套接字而言没有什么作用。因为对于一个 TCP 套接字来说，SIGIO 信号发生的几率太高了，所以 SIGIO 信号并不能告诉我们究竟发生了什么事情。

#### 在 TCP 连接中， SIGIO 信号将会在这个时候产生：

1.  在一个监听某个端口的套接字上成功的建立了一个新连接。
2.  一个断线的请求被成功的初始化。
3.  一个断线的请求成功的结束。
4.  套接字的某一个通道（发送通道或是接收通道）被关闭。
5.  套接字接收到新数据。
6.  套接字将数据发送出去。
7.  发生了一个异步 I/O 的错误。

    一个对信号驱动 I/O 比较实用的方面是NTP（网络时间协议 Network TimeProtocol）服务器，它使用 UDP。这个服务器的主循环用来接收从客户端发送过来的数据报数据包，然后再发送请求。对于这个服务器来说，记录下收到每一个数据包的具体时间是很重要的。

    因为那将是返回给客户端的值，客户端要使用这个数据来计算数据报在网络上来回所花费的时间。图 6-8 表示了怎样建立这样的一个 UDP 服务器。





## 异步I/O模式 
//比如写操作，只需用写，不一定写入磁盘(这就是异步I/O)的好处。异步IO的好处效率高。
    
当我们运行在异步 I/O 模式下时，我们如果想进行 I/O 操作，只需要告诉内核我们要进行 I/O 操作，然后内核会马上返回。具体的 I/O 和数据的拷贝全部由内核来完成，我们的程序可以继续向下执行。当内核完成所有的 I/O 操作和数据拷贝后，内核将通知我们的程序。
    
#### 异步 I/O 和  信号驱动I/O的区别是：
1. 信号驱动 I/O 模式下，内核在操作可以被操作的时候通知给我们的应用程序发送SIGIO 消息。

2. 异步 I/O 模式下，内核在所有的操作都已经被内核操作结束之后才会通知我们的应用程序。

## select，poll，epoll

###   Epoll 是何方神圣？

**Epoll** 可是当前在 Linux 下开发大规模并发网络程序的热门人选， Epoll 在 *Linux2.6* 内核中正式引入，和 **select** 相似，其实都 I/O 多路复用技术而已，并没有什么神秘的。

其实在Linux 下设计并发网络程序，向来不缺少方法，比如典型的 **Apache** 模型（ Process Per Connection ，简称PPC ）， TPC （ ThreadPer Connection ）模型，以及 select 模型和 poll 模型，那为何还要再引入 Epoll 这个东东呢？那还是有得说说的 …

## 2.  常用模型的缺点

如果不摆出来其他模型的缺点，怎么能对比出 Epoll 的优点呢。

### 2. 1 PPC/TPC 模型

这两种模型思想类似，就是让每一个到来的连接一边自己做事去，别再来烦我。只是 PPC 是为它开了一个进程，而 TPC 开了一个线程。可是别烦我是有代价的，它要时间和空间啊，连接多了之后，那么多的进程 / 线程切换，这开销就上来了；因此这类模型能接受的最大连接数都不会高，一般在几百个左右。

### 2. 2 select 模型

1.  最大并发数限制，因为一个进程所打开的 FD （文件描述符）是有限制的， 由FD_SETSIZE 设置，默认值是 1024/2048 ，因此 Select 模型的最大并发数就被相应限制了。自己改改这个 FD_SETSIZE ？想法虽好，可是先看看下面吧 …

2.  效率问题， select 每次调用都会线性扫描全部的 FD 集合，这样效率就会呈现线性下降，把 FD_SETSIZE 改大的后果就是，大家都慢慢来，什么？都超时了？？！！

3.  内核 / 用户空间内存拷贝问题，如何让内核把 FD 消息通知给用户空间呢？在这个问题上 select 采取了内存拷贝方法。

### 2. 3 poll 模型

基本上效率和select 是相同的，select 缺点的 2 和 3 它都没有改掉。

### 3.  Epoll 的提升

把其他模型逐个批判了一下，再来看看 Epoll 的改进之处吧，其实把 select 的缺点反过来那就是 Epoll 的优点了。

1.  Epoll 没有最大并发连接的限制，上限是最大可以打开文件的数目，这个数字一般远大于 2048, 一般来说这个数目和系统内存关系很大，具体数目可以 `cat /proc/sys/fs/file-max` 察看。

2.  效率提升， Epoll 最大的优点就在于它只管你“**活跃**”的连接，而跟连接总数无关，因此在实际的网络环境中， Epoll 的效率就会远远高于 select 和 poll 。

3.  内存拷贝， Epoll 在这点上使用了“**共享内存** ”，这个内存拷贝也省略了。


### 4.  Epoll 为什么高效

Epoll 的高效和其数据结构的设计是密不可分的，这个下面就会提到。

首先回忆一下select 模型，当有I/O 事件到来时，select 通知应用程序有事件到了快去处理，而应用程序必须轮询所有的 FD 集合，测试每个 FD 是否有事件发生，并处理事件；代码像下面这样：
```
int res = select(maxfd+1, &readfds,NULL, NULL, 120);
if (res > 0)
{
    for (int i = 0; i <MAX_CONNECTION; i++)
    {
        if (FD_ISSET(allConnection[i], &readfds))
        {
            handleEvent(allConnection[i]);
        }
    }
}
// if(res == 0) handle timeout, if(res < 0) handle error
```

Epoll 不仅会告诉应用程序有I/0事件到来，还会告诉应用程序相关的信息，这些信息是应用程序填充的，因此根据这些信息应用程序就能直接定位到事件，而不必遍历整个FD 集合。
```
int res = epoll_wait(epfd, events, 20,120);
for (int i = 0; i < res;i++)
{
    handleEvent(events[n]);
}
```

### 5.  Epoll 关键数据结构

前面提到Epoll 速度快和其数据结构密不可分，其关键数据结构就是：
```
struct epoll_event {
    __uint32_t  events;      // Epoll events
    epoll_data_t  data;      // User data variable
};

typedef union {
    void *ptr;
    int fd;
    __uint32_t u32;
    __uint64_t u64;

} epoll_data_t;
```
可见epoll_data 是一个 union 结构体 , 借助于它应用程序可以保存很多类型的信息 :fd 、指针等等。有了它，应用程序就可以直接定位目标了。

### socket服务端的实现，select和epoll的区别(必问)

select的本质是采用32个整数的32位，即32\*32= 1024来标识，fd值为1-1024。当fd的值超过1024限制时，就必须修改FD_SETSIZE的大小。这个时候就可以标识32\*max值范围的fd。

#### 对于单进程多线程，每个线程处理多个fd的情况，select是不适合的。

1. 所有的线程均是从1-32*max进行扫描，每个线程处理的均是一段fd值，这样做有点浪费

2. 1024上限问题，一个处理多个用户的进程，fd值远远大于1024

所以这个时候应该采用poll，

1. poll传递的是数组头指针和该数组的长度，只要数组的长度不是很长，性能还是很不错的，因为poll一次在内核中申请4K（一个页的大小来存放fd），尽量控制在4K以内

 1. epoll还是poll的一种优化，返回后不需要对所有的fd进行遍历，在内核中维持了fd的列表。select和poll是将这个内核列表维持在用户态，然后传递到内核中。但是只有在2. 6的内核才支持。

 1. epoll更适合于处理大量的fd ，且活跃fd不是很多的情况，毕竟fd较多还是一个串行的操作

 #### epoll哪些触发模式，有啥区别？(水平触发和边缘触发)
 （必须非常详尽的解释水平触发和边缘触发的区别，以及边缘触发在编程中要做哪些更多的确认）

 1.  epoll可以同时支持水平触发和边缘触发（Edge Triggered，只告诉进程哪些文件描述符刚刚变为就绪状态，它只说一遍，如果我们没有采取行动，那么它将不会再次告知，这种方式称为边缘触发），理论上边缘触发的性能要更高一些，但是代码实现相当复杂。

 1. epoll同样只告知那些就绪的文件描述符，而且当我们调用epoll_wait()获得就绪文件描述符时，返回的不是实际的描述符，而是一个代表就绪描述符数量的值，你只需要去epoll指定的一个数组中依次取得相应数量的文件描述符即可，这里也使用了内存映射（mmap）技术，这样便彻底省掉了这些文件描述符在系统调用时复制的开销。

 1. 另一个本质的改进在于epoll采用**基于事件的就绪通知方式**。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。

### 惊群现象
举一个很简单的例子，当你往一群鸽子中间扔一块食物，虽然最终只有一个鸽子抢到食物，但所有鸽子都会被惊动来争夺，没有抢到食物的鸽子只好回去继续睡觉，等待下一块食物到来。这样，每扔一块食物，都会惊动所有的鸽子，即为惊群。对于操作系统来说，多个进程/线程在等待同一资源是，也会产生类似的效果，其结果就是每当资源可用，所有的进程/线程都来竞争资源，造成的后果：

*    1）系统对用户进程/线程频繁的做无效的调度、上下文切换，系统系能大打折扣。
*    2）为了确保只有一个线程得到资源，用户必须对资源操作进行加锁保护，进一步加大了系统开销。

### 什么是惊群
最常见的例子就是对于socket描述符的accept操作，当多个用户进程/线程监听在同一个端口上时，由于实际只可能accept一次，因此就会产生惊群现象，当然前面已经说过了，这个问题是一个古老的问题，新的操作系统内核已经解决了这一问题。

linux内核解决惊群问题的方法

对于一些已知的惊群问题，内核开发者增加了一个“互斥等待”选项。一个互斥等待的行为与睡眠基本类似，主要的不同点在于：
* 1）当一个等待队列入口有 WQ_FLAG_EXCLUSEVE 标志置位, 它被添加到等待队列的尾部.  没有这个标志的入口项, 相反, 添加到开始.
* 2）当 wake_up 被在一个等待队列上调用时, 它在唤醒第一个有 WQ_FLAG_EXCLUSIVE 标志的进程后停止。

也就是说，对于互斥等待的行为，比如如对一个listen后的socket描述符，多线程阻塞accept时，系统内核只会唤醒所有正在等待此时间的队列的第一个，队列中的其他人则继续等待下一次事件的发生，这样就避免的多个线程同时监听同一个socket描述符时的惊群问题。


### 块设备和字符设备有什么区别

* (1) 字符设备：提供连续的数据流，应用程序可以顺序读取，通常不支持随机存取。相反，此类设备支持按字节/字符来读写数据。举例来说，调制解调器是典型的字符设备。
*  (2) 块设备：应用程序可以随机访问设备数据，程序可自行确定读取数据的位置。硬盘是典型的块设备，应用程序可以寻址磁盘上的任何位置，并由此读取数据。此外，数据的读写只能以块(通常是512B)的倍数进行。与字符设备不同，块设备并不支持基于字符的寻址。
    两种设备本身并没用严格的区分，主要是字符设备和块设备驱动程序提供的访问接口（file I/O API）是不一样的。本文主要就数据接口、访问接口和设备注册方法对两种设备进行比较。

### 用户态和内核态的区别

虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于**特权级的不同**，即权力的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序，
<span style="border-bottom:2px dashed blue;">当我们在系统中执行一个程序时，大部分时间是运行在用户态下的</span>，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态，

### linux文件系统：inode，inode存储了哪些东西，目录名，文件名存在哪里

#### inode包含文件的元信息，具体来说有以下内容：
　　
* 文件的字节数
* 文件拥有者的User ID
* 文件的Group ID
* 文件的读、写、执行权限
* 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。
* 链接数，即有多少文件名指向这个inode
* 文件数据block的位置

inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。
每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12. 8%。

每个inode都有一个号码，操作系统用inode号码来识别不同的文件。
这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。
表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。

一般情况下，文件名和inode号码是"一一对应"关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。
这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为"硬链接"（hard link）。

#### ln命令可以创建硬链接：ln 源文件 目标文件

文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的"软链接"（soft link）或者"符号链接（symbolic link）。
这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错："No such file or directory"。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode"链接数"不会因此发生变化。

ln -s命令可以创建软链接。：ln -s 源文文件或目录 目标文件或目录
+ [理解inode](http://www.ruanyifeng.com/blog/2011/12/inode.html)

#### /proc存在哪里（存在内存上）

/proc 文件系统是一个虚拟文件系统，通过它可以使用一种新的方法在 Linux® 内核空间和用户空间之间进行通信。在 /proc 文件系统中，我们可以将对虚拟文件的读写作为与内核中实体进行通信的一种手段，但是与普通文件不同的是，这些虚拟文件的内容都是动态创建的.
+ [使用 /proc 文件系统来访问 Linux 内核的内容](http://www.ibm.com/developerworks/cn/linux/l-proc.html)



## 网络：
### TCP和UDP区别

key:TCP是一种面向连接的、可靠的、字节流服务
1. 面向链接：TCP面向链接，面向连接意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须通过三次握手先建立一个TCP连接。在一个TCP中仅有两方彼此通信，多播和广播不能用于TCP。UDP是不可靠的传输，传输前不需要建立链接，可以应用多播和广播实现一对多的通信。

2. 可靠性：TCP提供端到端的流量控制，对收到的数据进行确认，采用超时重发，对失序的数据进行重新排序等机制保证数据通信的可靠性。而UDP是一种不可靠的服务，接收方可能不能收到发送方的数据报。

3. TCP是一种流模式的协议，UDP是一种数据报模式的协议。进程的每个输出操作都正好产生一个UDP数据报，并组装成一份待发送的IP数据报。TCP应用程序产生的全体数据与真正发送的单个IP数据报可能没有什么联系。TCP会有粘包和半包的现象。

4. 效率上：速度上，一般TCP速度慢，传输过程中需要对数据进行确认，超时重发，还要对数据进行排序。UDP没有这些机制所以速度快。数据比例，TCP头至少20个字节，UDP头8个字节，相对效率高。组装效率上：TCP头至少20个字节，UDP头8个字节，系统组装上TCP相对慢。

5. 用途上：用于TCP可靠性，http，ftp使用。而由于UDP速度快，视频，在线游戏多用UDP，保证实时性

    对于第三点的理解。TCP可能发送100个“包”，而接收到50个“包”，不是丢“包”了，而是每次接受的“包”都比发送的多，其实TCP并没有包的概念。例如，每次发10个字节，可能读得时候一次读了20个字节。TCP是一种流模式的协议，在接收到的缓存中按照发送的包得顺序自动按照顺序拼接好，因为数据基本来自同一个主机，而且是按照顺序发送过来的，TCP的缓存中存放的就是，连续的数据。感觉好像是多封装了一步比UDP。而UDP因为可能两个不同的主机，给同一个主机发送，（一个端口可能收到多个应用程序的数据），或者按照TCP那样合并数据，必然会造成数据错误。我觉得关键的原因还是，TCP是面向连接，而UDP是无连接的，这就导致，TCP接收的数据为一个主机发来且有序无误的，而UDP可能是多个主机发来的无序，可能错误的。


### TCP和UDP头部字节定义，

### TCP和UDP三次握手和四次挥手状态及消息类型,

### time_wait，close_wait状态产生原因，keepalive，


+ `TIME_WAIT：表示收到了对方的FIN报文，并发送出了ACK报文。 

TIME_WAIT状态下的TCP连接会等待2*MSL（Max Segment Lifetime，最大分段生存期，指一个TCP报文在Internet上的最长生存时间。每个具体的TCP协议实现都必须选择一个确定的MSL值，RFC 1122建议是2分钟，但BSD传统实现采用了30秒，Linux可以cat /proc/sys/net/ipv4/tcp_fin_timeout看到本机的这个值），然后即可回到CLOSED 可用状态了。如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。


如果使用了nginx代理，那么系统TIME_WAIT的数量会变得比较多，这是由于nginx代理使用了短链接的方式和后端交互的原因，使得nginx和后端的ESTABLISHED变得很少而TIME_WAIT很多。这不但发生在安装nginx的代理服务器上，而且也会使后端的app服务器上有大量的TIME_WAIT。查阅TIME_WAIT资料，发现这个状态很多也没什么大问题，但可能因为它占用了系统过多的端口，导致后续的请求无法获取端口而造成障碍。

虽然TIME_WAIT会造成一些问题，但是要完全枪毙掉它也是不正当的，虽然看起来这么做没什么错。 所以目前看来最好的办法是让每个TIME_WAIT早点过期。

#### 让每个TIME_WAIT早点过期,在linux上可以这么配置：

+ 让 **TIME_WAIT** 尽快回收，我也不知是多久，观察大概是一秒钟
    `echo "1" > /proc/sys/net/ipv4/tcp_tw_recycle`
+ 让TIME_WAIT状态可以重用，这样即使TIME_WAIT占满了所有端口，也不会拒绝新的请求造成障碍
    `echo "1" > /proc/sys/net/ipv4/tcp_tw_reuse`

很多文档都会建议两个参数都配置上，但是我发现只用修改tcp_tw_recycle就可以解决问题的了，TIME_WAIT重用TCP协议本身就是不建议打开的。

不能重用端口可能会造成系统的某些服务无法启动，比如要重启一个系统监控的软件，它用了40000端口，而这个端口在软件重启过程中刚好被使用了，就可能会重启失败的。linux默认考虑到了这个问题，有这么个设定：

+ 查看系统本地可用端口极限值
    `cat /proc/sys/net/ipv4/ip_local_port_range`

用这条命令会返回两个数字，默认是：32768 61000，说明这台机器本地能向外连接61000-32768=28232个连接，注意是本地向外连接，不是这台机器的所有连接，不会影响这台机器的80端口的对外连接数。但这个数字会影响到代理服务器（nginx）对app服务器的最大连接数，因为nginx对app是用的异步传输，所以这个环节的连接速度很快，所以堆积的连接就很少。假如nginx对app服务器之间的带宽出了问题或是app服务器有问题，那么可能使连接堆积起来，这时可以通过设定nginx的代理超时时间，来使连接尽快释放掉，一般来说极少能用到28232个连接。

因为有软件使用了40000端口监听，常常出错的话，可以通过设定ip_local_port_range的最小值来解决：

`echo "40001 61000" > /proc/sys/net/ipv4/ip_local_port_range`

但是这么做很显然把系统可用端口数减少了，这时可以把ip_local_port_range的最大值往上调，但是好习惯是使用不超过32768的端口来侦听服务，另外也不必要去修改ip_local_port_range数值成1024 65535之类的，意义不大。

因为使用了nginx代理，在windows下也会造成大量TIME_WAIT，当然windows也可以调整：

在注册表（regedit）的HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters上添加一个DWORD类型的值TcpTimedWaitDelay，值就是秒数，即可。

windows默认是重用TIME_WAIT，我现在还不知道怎么改成不重用的，本地端口也没查到是什么值，但这些都关系不大，都可以按系统默认运作。

### TIME_WAIT状态

根据TCP协议，主动发起关闭的一方，会进入TIME_WAIT状态，持续2\*MSL(Max Segment Lifetime)，缺省为240秒，在这个post中简洁的介绍了为什么需要这个状态。

值得一说的是，对于基于TCP的HTTP协议，关闭TCP连接的是Server端，这样，Server端会进入TIME_WAIT状态，可想而知，对于访问量大的Web Server，会存在大量的TIME_WAIT状态，假如server一秒钟接收1000个请求，那么就会积压240\*1000=240，000个TIME_WAIT的记录，维护这些状态给Server带来负担。当然现代操作系统都会用快速的查找算法来管理这些TIME_WAIT，所以对于新的TCP连接请求，判断是否hit中一个TIME_WAIT不会太费时间，但是有这么多状态要维护总是不好。

+ HTTP协议1. 1版规定default行为是Keep-Alive，

也就是会重用TCP连接传输多个request/response，一个主要原因就是发现了这个问题。还有一个方法减缓TIME_WAIT压力就是把系统的2*MSL时间减少，因为240秒的时间实在是忒长了点，对于Windows，修改注册表，在HKEY_LOCAL_MACHINE\ SYSTEM\CurrentControlSet\Services\ Tcpip\Parameters上添加一个DWORD类型的值TcpTimedWaitDelay，一般认为不要少于60，不然可能会有麻烦。
对于大型的服务，一台server搞不定，需要一个LB(Load Balancer)把流量分配到若干后端服务器上，如果这个LB是以NAT方式工作的话，可能会带来问题。假如所有从LB到后端Server的IP包的source address都是一样的(LB的对内地址），那么LB到后端Server的TCP连接会受限制，因为频繁的TCP连接建立和关闭，会在server上留下TIME_WAIT状态，而且这些状态对应的remote address都是LB的，LB的source port撑死也就60000多个(2^16=65536,1~1023是保留端口，还有一些其他端口缺省也不会用），每个LB上的端口一旦进入Server的TIME_WAIT黑名单，就有240秒不能再用来建立和Server的连接，这样LB和Server最多也就能支持300个左右的连接。如果没有LB，不会有这个问题，因为这样server看到的remote address是internet上广阔无垠的集合，对每个address，60000多个port实在是够用了。
一开始我觉得用上LB会很大程度上限制TCP的连接数，但是实验表明没这回事，LB后面的一台Windows Server 2003每秒处理请求数照样达到了600个，难道TIME_WAIT状态没起作用？用Net Monitor和netstat观察后发现，Server和LB的XXXX端口之间的连接进入TIME_WAIT状态后，再来一个LB的XXXX端口的SYN包，Server照样接收处理了，而是想像的那样被drop掉了。
    
翻书，从书堆里面找出覆满尘土的大学时代买的《UNIX Network Programming, Volume 1, Second Edition: Networking APIs: Sockets and XTI》，中间提到一句，对于BSD-derived实现，只要SYN的sequence number比上一次关闭时的最大sequence number还要大，那么TIME_WAIT状态一样接受这个SYN，难不成Windows也算BSD-derived?有了这点线索和关键字(BSD)，找到这个post，在NT4. 0的时候，还是和BSD-derived不一样的，不过Windows Server 2003已经是NT5. 2了，也许有点差别了。
    做个试验，用Socket API编一个Client端，每次都Bind到本地一个端口比如2345，重复的建立TCP连接往一个Server发送Keep-Alive=false的HTTP请求，Windows的实现让sequence number不断的增长，所以虽然Server对于Client的2345端口连接保持TIME_WAIT状态，但是总是能够接受新的请求，不会拒绝。那如果SYN的Sequence Number变小会怎么样呢？同样用Socket API，不过这次用Raw IP，发送一个小sequence number的SYN包过去，Net Monitor里面看到，这个SYN被Server接收后如泥牛如海，一点反应没有，被drop掉了。
    按照书上的说法，BSD-derived和Windows Server 2003的做法有安全隐患，不过至少这样至少不会出现TIME_WAIT阻止TCP请求的问题，当然，客户端要配合，保证不同TCP连接的sequence number要上涨不要下降。

### Socket中的TIME_WAIT状态
在高并发短连接的server端，当server处理完client的请求后立刻closesocket此时会出现time_wait状态然后如果client再并发2000个连接，此时部分连接就连接不上了,用linger强制关闭可以解决此问题，但是linger会导致数据丢失，linger值为0时是强制关闭,无论并发多少多能正常连接上,如果非0会发生部分连接不上的情况!（可调用setsockopt设置套接字的linger延时标志，同时将延时时间设置为0。）
TCP/IP的RFC文档。

TIME_WAIT是TCP连接断开时必定会出现的状态。 是无法避免掉的，这是TCP协议实现的一部分。 在WINDOWS下，可以修改注册表让这个时间变短一些 time_wait的时间为2msl,默认为4min. 你可以通过改变这个变量: TcpTimedWaitDelay 把它缩短到30s TCP要保证在所有可能的情况下使得所有的数据都能够被投递。当你关闭一个socket时，主动关闭一端的socket将进入TIME_WAIT状态，而被动关闭一方则转入CLOSED状态，这的确能够保证所有的数据都被传输。当一个socket关闭的时候，是通过两端互发信息的四次握手过程完成的，当一端调用close()时，就说明本端没有数据再要发送了。这好似看来在握手完成以后，socket就都应该处于关闭CLOSED状态了。但这有两个问题，首先，我们没有任何机制保证最后的一个ACK能够正常传输，第二，网络上仍然有可能有残余的数据包(wandering duplicates)，我们也必须能够正常处理。 通过正确的状态机，我们知道双方的关闭过程如下

    图
假设最后一个ACK丢失了，服务器会重发它发送的最后一个FIN，所以客户端必须维持一个状态信息，以便能够重发ACK；如果不维持这种状态，客户端在接收到FIN后将会响应一个RST，服务器端接收到RST后会认为这是一个错误。如果TCP协议能够正常完成必要的操作而终止双方的数据流传输，就必须完全正确的传输四次握手的四个节，不能有任何的丢失。这就是为什么socket在关闭后，仍然处于 TIME_WAIT状态，因为他要等待以便重发ACK。
如果目前连接的通信双方都已经调用了close()，假定双方都到达CLOSED状态，而没有TIME_WAIT状态时，就会出现如下的情况。现在有一个新的连接被建立起来，使用的IP地址与端口与先前的完全相同，后建立的连接又称作是原先连接的一个化身。还假定原先的连接中有数据报残存于网络之中，这样新的连接收到的数据报中有可能是先前连接的数据报。为了防止这一点，TCP不允许从处于TIME_WAIT状态的socket建立一个连接。处于TIME_WAIT状态的socket在等待两倍的MSL时间以后（之所以是两倍的MSL，是由于MSL是一个数据报在网络中单向发出到认定丢失的时间，一个数据报有可能在发送图中或是其响应过程中成为残余数据报，确认一个数据报及其响应的丢弃的需要两倍的MSL），将会转变为CLOSED状态。这就意味着，一个成功建立的连接，必然使得先前网络中残余的数据报都丢失了。
由于TIME_WAIT状态所带来的相关问题，我们可以通过设置SO_LINGER标志来避免socket进入TIME_WAIT状态，这可以通过发送RST而取代正常的TCP四次握手的终止方式。但这并不是一个很好的主意，TIME_WAIT对于我们来说往往是有利的。

+ 客户I端与服务器端建立TCP/IP连接后关闭SOCKET后，服务器端连接的端口 状态为TIME_WAIT 是不是所有执行主动关闭的socket都会进入TIME_WAIT状态呢？

有没有什么情况使主动关闭的socket直接进入CLOSED状态呢？
主动关闭的一方在发送最后一个 ack 后 就会进入 TIME_WAIT 状态 停留2MSL（max segment lifetime）时间这个是TCP/IP必不可少的，也就是“解决”不了的。

也就是TCP/IP设计者本来是这么设计的 主要有两个原因

1. 防止上一次连接中的包，迷路后重新出现，影响新连接
（经过2MSL，上一次连接中所有的重复包都会消失）
2. 可靠的关闭TCP连接 在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发 fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以 主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。

TIME_WAIT 并不会占用很大资源的，除非受到攻击。
还有，如果一方 send 或 recv 超时，就会直接进入 CLOSED 状态

什么是滑动窗口，超时重传，

列举你所知道的tcp选项，

connect会阻塞检测及防止，socket什么情况下可读？

connect会阻塞，怎么解决?(必考必问)

最通常的方法最有效的是加定时器；也可以采用非阻塞模式。
设置非阻塞，返回之后用select检测状态)
如果select返回可读，结果只读到0字节，什么情况？
某个套接字集合中没有准备好，可能会select内存用FD_CLR清该位为0；


+ socket什么情况下可读？

每次读操作返回前都要检查是否还有剩余数据没读完，如果是的话保持数据有效标志，不这样设计的话会出现明显的不一致，那就是数据在读缓冲但没有读有效标志。


### 相关书籍

+ 语言类：

C:C程序设计语言（K&R）->C和指针->C专家编程->C陷阱与缺陷->你必须知道的495个C语言问题

C++: C++ primer -> effective C++->深度探索C++对象模型 ->stl源码分析->C++必知必会

java：java编程思想->java并发编程->深入理解Java虚拟机：JVM高级特性与最佳实践

+ 算法和数据结构：

算法导论->数据结构与算法分析(维斯)->编程之美->剑指offer

+ 操作系统：

深入理解计算机操作系统->编译原理（龙书）
    鸟哥的linux私房菜->linux内核设计与实现->深入理解linux内核
    linux shell脚本攻略（短小精悍）

+ 网络编程：

TCP/IP协议详解v1->
unix高级环境编程->
unix网络编程（卷1&卷2）->
unix编程艺术(进阶)

+ 视野：

大型网站技术架构：核心原理与案例分析，
深入理解nginx：模块开发与架构解析，
大规模分布式存储系统 : 原理解析与架构实战

+ 其他：
程序员自我修养，
    重构，
    编写可读代码的艺术，
    headfirst设计模式

## 相关网络资源

    Coolshell：http://coolshell.cn/
    Matrix67大牛的博客：http://www.matrix67.com/blog/。
    July的CSDN博客：http://blog.csdn.net/v_JULY_v。
    何海涛博客：http://zhedahht.blog.163.com/。
    笔试面试的经典：Cracking the coding interview--问题与解答：
    http://hawstein. com/posts/ctci-solutions-contents. html
    LeetCode：http://leetcode. com/
    这里有不少笔试题集锦：http://blog.csdn.net/hackbuteer1
    程序员编程艺术：面试和算法心得http://taop.marchtea.com/

## 本文参考资料

江南烟雨 http://blog.csdn.net/xiajun07061225/article/details/12844801
胡成 腾讯后台开发面试题及答案
